# âš™ï¸ functions.py (v0.2)
# ì´ íŒŒì¼ì€ ë°ì´í„°, ìƒíƒœ ë³€ê²½(ì½œë°±), UI ë Œë”ë§ì„ ëª¨ë‘ ë‹´ë‹¹í•©ë‹ˆë‹¤.

import streamlit as st
import numpy as np  # (ë”ë¯¸ ê·¸ë˜í”„ìš©)
import json
from .data import MOCK_DB  # (ê°™ì€ í´ë”ì˜ data.pyì—ì„œ MOCK_DB ê°€ì ¸ì˜¤ê¸°)

#========================#
# --- ê¸°ë³¸ ë°ì´í„° ë¡œì§ ---#
#========================#

def get_all_articles() -> list:
    """[To. DE] DBì— ìˆëŠ” ëª¨ë“  ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return list(MOCK_DB.values())

def get_article_by_id(article_id: str) -> dict:
    """[To. DE] íŠ¹ì • IDì˜ ê¸°ì‚¬ ìƒì„¸ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return MOCK_DB.get(article_id)

# Gemini í´ë¼ì´ì–¸íŠ¸ / ëª¨ë¸ ì´ë¦„ì€ app.pyì—ì„œ í• ë‹¹
client = None
MODEL_NAME = None


#========================#
# --- Gemini ìš”ì•½ í•¨ìˆ˜ ---#
#========================#

def summarize_article_with_gemini(article_text: str) -> str:
    """
    Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” í•¨ìˆ˜.

    :param article_text: ìš”ì•½í•  ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ (str)
    :return: ìš”ì•½ëœ í…ìŠ¤íŠ¸ (str) ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€
    """
    if not client or not MODEL_NAME:
        print("âŒ 'summarize_article_with_gemini' í˜¸ì¶œ ì‹¤íŒ¨: Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return "ìš”ì•½ ì˜¤ë¥˜: Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”."

    if not article_text or len(article_text.strip()) < 10:
        return "ë³¸ë¬¸ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤."

    # ì‹œìŠ¤í…œ ì—­í•  + ìš”êµ¬ì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ ìƒë‹¨ì— ë¶™ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
    system_instruction = (
        "ë‹¹ì‹ ì€ ë‰´ìŠ¤ ìš”ì•½ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
        "ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ë‚´ìš©ë§Œ íŒŒì•…í•˜ì—¬ 2~3ê°œì˜ ê°ê´€ì ì´ê³  ì™„ê²°ëœ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. "
        "ìš”ì•½ë¬¸ì—ëŠ” 'í•„ìëŠ”', 'ê¸°ìëŠ”', 'ì €ìëŠ”'ê³¼ ê°™ì€ í‘œí˜„ì´ë‚˜, "
        "í…ìŠ¤íŠ¸ ë‚´ìš©ê³¼ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” ì„œë¡ /ê²°ë¡ ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”. "
        "ëª¨ë“  ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ëë‚˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ì—°ê²°ë˜ë„ë¡ ì‘ì„±í•˜ì‹­ì‹œì˜¤."
    )

    user_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”:\n\n{article_text}"

    # ìµœì¢… í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
    prompt = system_instruction + "\n\n[ê¸°ì‚¬]\n" + user_prompt

    try:
        config = {
            "max_output_tokens": 2048,
            "temperature": 0.3,
        }

        # google-genai êµ¬ë²„ì „: config= ë§Œ ì§€ì›
        response = client.models.generate_content(
            model=f"models/{MODEL_NAME}",
            contents=prompt,
            config=config,
        )

        if response.text is not None:
            return response.text.strip()

        # response.textê°€ Noneì¸ ê²½ìš°
        reason = "ì•Œ ìˆ˜ ì—†ëŠ” ì´ìœ ë¡œ ëª¨ë¸ì´ í…ìŠ¤íŠ¸ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        try:
            if response.candidates and response.candidates[0].finish_reason:
                reason = f"ëª¨ë¸ ì¢…ë£Œ ì´ìœ : {response.candidates[0].finish_reason.name}"
        except Exception:
            pass

        snippet = article_text[:50].replace("\n", " ")
        print(f"âš ï¸ ìš”ì•½ ì‹¤íŒ¨ (ê¸°ì‚¬ ì¼ë¶€: {snippet}...): {reason}")
        return f"ìš”ì•½ ì‹¤íŒ¨: {reason}"

    except Exception as e:
        print(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ë¶„ë¦¬
        msg = str(e)
        if "API_KEY" in msg.upper():
            return "ìš”ì•½ ì˜¤ë¥˜: API í‚¤ê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        if "DeadlineExceeded" in msg:
            return "ìš”ì•½ ì˜¤ë¥˜: ìš”ì²­ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."
        return "ìš”ì•½ ì˜¤ë¥˜: ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."


def get_summary(article_text: str) -> str:
    """[To. M1 (ìš”ì•½)] ê¸°ì‚¬ ë³¸ë¬¸ì„ ë°›ì•„ ìš”ì•½ë¬¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    snippet = article_text[:30].replace("\n", " ")
    print(f"ìš”ì•½ ìš”ì²­ ì‹œì‘ (ë³¸ë¬¸ ì¼ë¶€: {snippet}...)")
    with st.spinner("ìš”ì•½ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
        summary = summarize_article_with_gemini(article_text)
    snippet_sum = summary[:30].replace("\n", " ")
    print(f"ìš”ì•½ ì™„ë£Œ (ìš”ì•½ë¬¸ ì¼ë¶€: {snippet_sum}...)")
    return summary


#==========================#
# --- ì‹ ë¢°ë„ íŒë³„ íŒŒíŠ¸ ---#
#==========================#

def get_trust_score(article_text: str, source: str) -> dict:
    """
    [To. PM (ì‹ ë¢°)] ê¸°ì‚¬ ë³¸ë¬¸ê³¼ ì¶œì²˜ë¥¼ ë°›ì•„ ì‹ ë¢°ë„ ì ìˆ˜ì™€ ê·¼ê±°ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    v0.2: TELLER í”„ë ˆì„ì›Œí¬ ì•„ì´ë””ì–´ë¥¼ ê°„ë‹¨íˆ ì°¨ìš©í•œ
          LLM + ê·œì¹™ ê¸°ë°˜ ìµœì†Œ êµ¬í˜„ (ML ë¯¸ì‚¬ìš©)
    """
    # 0. ê¸°ë³¸ ë°©ì–´ ë¡œì§: í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ or ë³¸ë¬¸ ë„ˆë¬´ ì§§ìŒ

    def _simple_source_heuristic(src: str) -> dict:
        base = 60
        if not src:
            base -= 10
        else:
            high_trust_keywords = ["ì—°í•©ë‰´ìŠ¤", "KBS", "MBC", "SBS", "YTN", "BBC", "Reuters", "ë¡œì´í„°", "APí†µì‹ "]
            low_trust_keywords = ["ë¸”ë¡œê·¸", "ì¹´í˜", "ì»¤ë®¤ë‹ˆí‹°", "ìœ íŠœë¸Œ", "SNS", "ì¹´ë”ë¼"]
            if any(k in src for k in high_trust_keywords):
                base += 20
            if any(k in src for k in low_trust_keywords):
                base -= 20
        base = max(0, min(100, base))
        return {
            "score": base,
            "verdict": "uncertain",
            "reason": "Gemini ì—†ì´ ê°„ë‹¨í•œ ì¶œì²˜ íœ´ë¦¬ìŠ¤í‹±ìœ¼ë¡œ ì¶”ì •í•œ ì‹ ë¢°ë„ì…ë‹ˆë‹¤.",
            "framework_version": "TELLER-v0.2-heuristic"
        }

    def _parse_json_from_text(text: str) -> dict:
        """```json ì½”ë“œë¸”ëŸ­ì´ë‚˜ ì•ë’¤ ì„¤ëª…ì´ ì„ì—¬ ìˆì–´ë„ JSON ë¶€ë¶„ë§Œ ë½‘ì•„ íŒŒì‹±"""
        if not text:
            raise ValueError("ë¹ˆ ì‘ë‹µ")

        stripped = text.strip()
        # ```json ... ``` ì œê±° ì‹œë„
        if stripped.startswith("```"):
            # ì½”ë“œë¸”ëŸ­ í—¤ë”/í‘¸í„° ì œê±° (ì•„ì£¼ ëŸ¬í”„í•˜ê²Œ)
            stripped = stripped.strip("`")
        start = stripped.find("{")
        end = stripped.rfind("}")
        if start == -1 or end == -1 or end <= start:
            raise ValueError(f"JSON êµ¬ê°„ì„ ì°¾ì§€ ëª»í•¨: {stripped[:100]}")
        json_str = stripped[start:end+1]
        return json.loads(json_str)

    if client is None or MODEL_NAME is None:
        print("âŒ 'get_trust_score' í˜¸ì¶œ ì‹¤íŒ¨: Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return _simple_source_heuristic(source)

    if not article_text or len(article_text.strip()) < 30:
        return {
            "score": 50,
            "verdict": "uncertain",
            "reason": "ë³¸ë¬¸ì´ ë„ˆë¬´ ì§§ì•„ ì‹ ë¢°ë„ í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.",
            "framework_version": "TELLER-v0.2-minimal"
        }

    # 1. TELLER-lite 1ì°¨ í”„ë¡¬í”„íŠ¸
    system_instruction = (
        "ë‹¹ì‹ ì€ TELLER í”„ë ˆì„ì›Œí¬ë¥¼ ì‘ìš©í•œ ë‰´ìŠ¤ ì‹ ë¢°ë„ í‰ê°€ìì…ë‹ˆë‹¤. "
        "ê¸°ì‚¬ì˜ ì¶œì²˜, ì¦ê±° ìœ ë¬´, í‘œí˜„ ë°©ì‹, ë…¼ë¦¬ ì¼ê´€ì„±, í´ë¦­ë² ì´íŠ¸ ìœ„í—˜ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ "
        "ê° í•­ëª©ì„ 0~2ì (0=ë§¤ìš° ì˜ì‹¬, 1=ì• ë§¤, 2=ì‹ ë¢° ê°€ëŠ¥)ìœ¼ë¡œ ì±„ì í•˜ê³ , ê° ê¸°ì¤€ì— ëŒ€í•´ í•œ ë¬¸ì¥ ê·¼ê±°ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤. "
        "ë˜í•œ ì „ì²´ì ì¸ ì§„ì‹¤ì„± íŒë‹¨(verdict)ê³¼ ê·¸ ê·¼ê±°(overall_reason)ë¥¼ ì œê³µí•©ë‹ˆë‹¤. "
        "ë°˜ë“œì‹œ ìœ íš¨í•œ JSONë§Œ ì¶œë ¥í•´ì•¼ í•˜ë©°, JSON ì´ì™¸ì˜ í…ìŠ¤íŠ¸ëŠ” ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤."
    )

    user_prompt = f"""
ë‹¤ìŒì€ í•˜ë‚˜ì˜ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ê·¸ ì¶œì²˜ì…ë‹ˆë‹¤.

[ì¶œì²˜]
{source or "ë¯¸ìƒ"}

[ê¸°ì‚¬ ë³¸ë¬¸]
{article_text}

ì•„ë˜ 5ê°œ ê¸°ì¤€ì— ëŒ€í•´ ê°ê° 0~2ì ì˜ ì •ìˆ˜ ì ìˆ˜ì™€ í•œ ë¬¸ì¥ ê·¼ê±°ë¥¼ í‰ê°€í•´ ì£¼ì„¸ìš”.
ì ìˆ˜: 0=ë§¤ìš° ì˜ì‹¬ìŠ¤ëŸ½ë‹¤, 1=ì• ë§¤í•˜ë‹¤, 2=ì‹ ë¢° ê°€ëŠ¥í•˜ë‹¤.

1) source_credibility: ì¶œì²˜ì˜ ì¼ë°˜ì ì¸ ì‹ ë¢°ë„ëŠ” ì–´ëŠ ì •ë„ì¸ê°€?
2) evidence_support: ê¸°ì‚¬ ë‚´ìš©ì´ êµ¬ì²´ì ì¸ ì‚¬ì‹¤, ìˆ˜ì¹˜, ì¸ìš© ë“± ê²€ì¦ ê°€ëŠ¥í•œ ì¦ê±°ì— ì–¼ë§ˆë‚˜ ê¸°ë°˜í•˜ëŠ”ê°€?
3) style_neutrality: ê¸°ì‚¬ í‘œí˜„ì´ ê³¼ë„í•˜ê²Œ ì„ ì •ì ì´ê±°ë‚˜ ê°ì •ì ì´ì§€ ì•Šê³ , ì¤‘ë¦½ì ì¸ê°€?
4) logical_consistency: ê¸°ì‚¬ ë‚´ë¶€ì— ë…¼ë¦¬ì  ëª¨ìˆœì´ë‚˜ ìê¸°ëª¨ìˆœì´ ì—†ì´ ì¼ê´€ì ì¸ê°€?
5) clickbait_risk: ì œëª©/ë‚´ìš©ì´ í´ë¦­ì„ ìœ ë„í•˜ëŠ” ê³¼ì¥Â·ì„ ì •ì  í‘œí˜„ì— í¬ê²Œ ì˜ì¡´í•˜ì§€ ì•ŠëŠ”ê°€?

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ, ê³µë°±ê³¼ ì¤„ë°”ê¿ˆì€ ììœ ë¡­ê²Œ ì‚¬ìš©í•˜ë˜ ìœ íš¨í•œ JSONì´ ë˜ë„ë¡ ì‘ë‹µí•˜ì„¸ìš”.

{{
  "per_criteria": {{
    "source_credibility": {{"score": 0, "reason": "..." }},
    "evidence_support":   {{"score": 0, "reason": "..." }},
    "style_neutrality":   {{"score": 0, "reason": "..." }},
    "logical_consistency":{{"score": 0, "reason": "..." }},
    "clickbait_risk":     {{"score": 0, "reason": "..." }}
  }},
  "verdict": "likely_true ë˜ëŠ” likely_false ë˜ëŠ” uncertain ì¤‘ í•˜ë‚˜",
  "overall_reason": "ì „ì²´ì ì¸ íŒë‹¨ ê·¼ê±°ë¥¼ í•œêµ­ì–´ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì„œìˆ "
}}
"""

    full_prompt = system_instruction + "\n\n[í‰ê°€ ëŒ€ìƒ ê¸°ì‚¬]\n" + user_prompt

    def _call_llm(prompt: str) -> str:
        """LLM í˜¸ì¶œ: JSON ëª¨ë“œ ê°•ì œ + í† í° ì¦ëŸ‰ + ì•ˆì „ ì„¤ì • í•´ì œ"""
        try:
            # 1. ì•ˆì „ ì„¤ì • (ìœ ì§€)
            safety_settings = [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
            ]

            # 2. ì„¤ì • ê°•í™” (JSON ëª¨ë“œ + í† í° 8ë°° ì¦ëŸ‰)
            config = {
                "max_output_tokens": 8192,   # 1024 -> 8192 (ì§¤ë¦¼ ë°©ì§€)
                "temperature": 0.1,
                "response_mime_type": "application/json", # <--- í•µì‹¬: ë¬´ì¡°ê±´ JSONìœ¼ë¡œë§Œ ë±‰ìŒ
                "safety_settings": safety_settings,
            }

            # 3. í˜¸ì¶œ
            response = client.models.generate_content(
                model=f"models/{MODEL_NAME}",
                contents=prompt,
                config=config,
            )

            # 4. í…ìŠ¤íŠ¸ ì¶”ì¶œ
            # JSON ëª¨ë“œë¥¼ ì“°ë©´ response.textê°€ ê¹”ë”í•˜ê²Œ ë–¨ì–´ì§ˆ í™•ë¥ ì´ 99.9%ì…ë‹ˆë‹¤.
            if hasattr(response, "text"):
                return response.text
            
            # í˜¹ì‹œë¼ë„ text ì†ì„±ì´ ì•ˆ ì¡í ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ë°±ì—…
            if hasattr(response, "candidates") and response.candidates:
                return response.candidates[0].content.parts[0].text

            return ""

        except Exception as e:
            print(f"LLM í˜¸ì¶œ ì˜¤ë¥˜: {e}")
            # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ JSON ë¬¸ìì—´ ë¦¬í„´í•˜ì—¬ íŒŒì‹± ì—ëŸ¬ ë°©ì§€
            return "{}"
              
    try:
        with st.spinner("ì‹ ë¢°ë„ í‰ê°€ ì¤‘... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”."):
            raw_text = _call_llm(full_prompt)

        print("===== RAW TRUST RESPONSE BEGIN =====")
        print(raw_text)
        print("===== RAW TRUST RESPONSE END =====")

        # 1ì°¨ í˜¸ì¶œì—ì„œ ë¹ˆ ì‘ë‹µì´ë©´ â†’ ë‹¨ìˆœ ë°±ì—… í”„ë¡¬í”„íŠ¸ë¡œ í•œ ë²ˆ ë” ì‹œë„
        if not raw_text:
            print("âš ï¸ 1ì°¨ ì‹ ë¢°ë„ í”„ë¡¬í”„íŠ¸ì—ì„œ ë¹ˆ ì‘ë‹µ. ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸ë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            simple_prompt = f"""
ë‹¹ì‹ ì€ ë‰´ìŠ¤ì˜ ì§„ì‹¤ì„±ì„ í‰ê°€í•˜ëŠ” í•œêµ­ì–´ í‰ê°€ìì…ë‹ˆë‹¤.

ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ì™€ ì¶œì²˜ë¥¼ ë³´ê³ , ì „ì²´ì ì¸ ì‹ ë¢°ë„ë¥¼ 0~100 ì‚¬ì´ ì •ìˆ˜(score)ë¡œ í‰ê°€í•˜ê³ ,
ì§„ì‹¤ì„± íŒë‹¨(verdict)ê³¼ í•œ ë¬¸ì¥ ì´ìœ (reason)ë¥¼ JSONìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”.

í˜•ì‹:
{{
  "score": 0,
  "verdict": "likely_true ë˜ëŠ” likely_false ë˜ëŠ” uncertain ì¤‘ í•˜ë‚˜",
  "reason": "..."
}}

[ì¶œì²˜]
{source or "ë¯¸ìƒ"}

[ê¸°ì‚¬ ë³¸ë¬¸]
{article_text}
"""
            raw_text = _call_llm(simple_prompt)
            print("===== RAW SIMPLE TRUST RESPONSE BEGIN =====")
            print(raw_text)
            print("===== RAW SIMPLE TRUST RESPONSE END =====")

            if not raw_text:
                raise ValueError("2ì°¨ ë‹¨ìˆœ í”„ë¡¬í”„íŠ¸ì—ì„œë„ ë¹ˆ ì‘ë‹µ")

            # simple ëª¨ë“œ íŒŒì‹±
            data = _parse_json_from_text(raw_text)
            score = int(data.get("score", 50))
            verdict = data.get("verdict", "uncertain")
            reason = data.get("reason", "LLMì˜ ë‹¨ìˆœ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤.")
            score = max(0, min(100, score))
            if not isinstance(verdict, str):
                verdict = "uncertain"
            if not isinstance(reason, str) or len(reason.strip()) < 3:
                reason = "LLMì˜ ë‹¨ìˆœ í‰ê°€ ê²°ê³¼ì…ë‹ˆë‹¤."
            return {
                "score": score,
                "verdict": verdict,
                "reason": reason,
                "per_criteria": {},
                "framework_version": "TELLER-v0.2-simple"
            }

        # 1ì°¨(TELLER-lite) ì‘ë‹µ íŒŒì‹±
        try:
            data = json.loads(raw_text)
        except Exception:
            data = _parse_json_from_text(raw_text)

        per_criteria = data.get("per_criteria", {}) or {}

        weights = {
            "source_credibility": 1.5,
            "evidence_support": 1.5,
            "style_neutrality": 1.0,
            "logical_consistency": 1.0,
            "clickbait_risk": 1.0,
        }
        total_weight = sum(weights.values())
        weighted_sum = 0.0

        for key, w in weights.items():
            score_val = per_criteria.get(key, {}).get("score", 1)
            try:
                score_float = float(score_val)
            except Exception:
                score_float = 1.0
            score_float = max(0.0, min(2.0, score_float))
            weighted_sum += (score_float / 2.0) * 100.0 * w

        overall_score = int(round(weighted_sum / total_weight))

        verdict = data.get("verdict", "uncertain")
        if not isinstance(verdict, str):
            verdict = "uncertain"

        overall_reason = data.get("overall_reason")
        if not isinstance(overall_reason, str) or len(overall_reason.strip()) < 5:
            label_map = {
                "source_credibility": "ì¶œì²˜ ì‹ ë¢°ë„",
                "evidence_support": "ì¦ê±° ê¸°ë°˜ì„±",
                "style_neutrality": "í‘œí˜„ ì¤‘ë¦½ì„±",
                "logical_consistency": "ë…¼ë¦¬ ì¼ê´€ì„±",
                "clickbait_risk": "í´ë¦­ë² ì´íŠ¸ ìœ„í—˜ë„",
            }
            reason_list = []
            for k, label in label_map.items():
                r = per_criteria.get(k, {}).get("reason")
                if isinstance(r, str) and r.strip():
                    reason_list.append(f"{label}: {r.strip()}")
            overall_reason = " / ".join(reason_list) if reason_list else "LLMì˜ ê¸°ì¤€ë³„ í‰ê°€ë¥¼ ì¢…í•©í•˜ì—¬ ì‚°ì¶œí•œ ì‹ ë¢°ë„ ì ìˆ˜ì…ë‹ˆë‹¤."

        return {
            "score": overall_score,
            "verdict": verdict,
            "reason": overall_reason,
            "per_criteria": per_criteria,
            "framework_version": "TELLER-v0.2-rule"
        }

    except Exception as e:
        print(f"ì‹ ë¢°ë„ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        fallback = _simple_source_heuristic(source)
        fallback["framework_version"] = "TELLER-v0.2-heuristic-fallback"
        return fallback


#==========================#
# --- ì¶”ì²œ (ë”ë¯¸ êµ¬í˜„) ---#
#==========================#

def get_recommendations(user_id: str = "default_user") -> list:
    """[To. M2 (ì¶”ì²œ)] ì‚¬ìš©ì ID ê¸°ë°˜ìœ¼ë¡œ ì¶”ì²œ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return [MOCK_DB['news_002'], MOCK_DB['news_004'], MOCK_DB['news_001']]


#===========================#
# --- ìƒíƒœ ë³€ê²½ ì½œë°± í•¨ìˆ˜ ---#
#===========================#

def select_article(article_id: str):
    """(ì½œë°±) ìƒì„¸ í˜ì´ì§€ë¡œ ì´ë™"""
    st.session_state['selected_article_id'] = article_id
    st.session_state['admin_mode'] = False 

def show_main_page():
    """(ì½œë°±) ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™ (ëª¨ë“  ìƒíƒœ ì´ˆê¸°í™”)"""
    st.session_state['selected_article_id'] = None
    st.session_state['search_executed'] = False
    st.session_state['search_query'] = ""
    st.session_state['admin_mode'] = False

def execute_search():
    """(ì½œë°±) ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ë¡œ ì´ë™"""
    st.session_state['search_executed'] = True
    st.session_state['selected_article_id'] = None
    st.session_state['admin_mode'] = False

def go_to_admin(): 
    """(ì½œë°±) ê´€ë¦¬ì ëª¨ë“œë¡œ ì „í™˜"""
    st.session_state['admin_mode'] = True
    st.session_state['selected_article_id'] = None 
    st.session_state['search_executed'] = False


#=========================#
# --- UI ë Œë”ë§ í•¨ìˆ˜ë“¤ ---#
#=========================#

def render_admin_page():
    """ê´€ë¦¬ì í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.title("ğŸ› ï¸ ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ (Admin Mode)")
    st.button("â€¹ â€¹ ì‚¬ìš©ì ëª¨ë“œë¡œ ëŒì•„ê°€ê¸°", on_click=show_main_page)
    st.markdown("---")

    col1, col2 = st.columns([2, 1]) 
    with col1:
        st.subheader("ì¼ê°„ í™œì„± ì‚¬ìš©ì(DAU) ë¡œê·¸ (Dummy Graph)")
        chart_data = np.random.randn(30, 3)
        st.line_chart(chart_data)
        st.info("ì´ê³³ì— ClickHouseì—ì„œ ì§‘ê³„í•œ ì‚¬ìš©ì ë¡œê·¸ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

    with col2:
        st.subheader("ê´€ë¦¬ì ê¸°ëŠ¥ (Dummy)")
        if st.button("âš™ï¸ ì¼ì¼ ê¸°ì‚¬ ìë™ í¬ë¡¤ë§ ì‹¤í–‰ (Dummy)"):
            with st.spinner("í¬ë¡¤ë§ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ê°€ì§œ)"):
                import time
                time.sleep(2)
                st.success("ì˜¤ëŠ˜ì˜ ê¸°ì‚¬ 100ê°œê°€ í¬ë¡¤ë§ë˜ì—ˆìŠµë‹ˆë‹¤! (ê°€ì§œ)")
        
        st.divider() 
        st.subheader("ì£¼ìš” ì§€í‘œ (Dummy)")
        m_col1, m_col2 = st.columns(2)
        with m_col1:
            st.metric("ì´ ê¸°ì‚¬ ìˆ˜ (DB)", "5", "+5 (ì˜¤ëŠ˜)")
        with m_col2:
            st.metric("ì´ ì‚¬ìš©ì ìˆ˜", "1", "+0 (ì˜¤ëŠ˜)")


def render_detail_page(article_id: str):
    """ìƒì„¸ ê¸°ì‚¬ í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤. (UI/UX ê°œì„ íŒ)"""
    article = get_article_by_id(article_id)
    
    if article:
        # --- ë©”ì¸ ì»¨í…ì¸  ì˜ì—­ ---
        st.button("â€¹ ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=show_main_page)
        st.header(article['title'])
        
        # ë©”íƒ€ ì •ë³´ ë°°ì§€ í˜•íƒœë¡œ í‘œì‹œ
        c1, c2 = st.columns([0.8, 0.2])
        with c1:
            st.caption(f"ğŸ“° ì¶œì²˜: **{article['source']}** | ğŸ”— ì›ë¬¸: {article['url']}")
        
        st.markdown("---")
        st.subheader("ê¸°ì‚¬ ë³¸ë¬¸")
        # ê°€ë…ì„±ì„ ìœ„í•´ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ ê°•í™”
        st.markdown(article['full_text'].replace("\n", "  \n\n")) 
        st.markdown("---")

        # --- ì‚¬ì´ë“œë°” AI ë¶„ì„ ì˜ì—­ (ëŒ€í­ ê°œì„ ) ---
        trust_info = get_trust_score(article['full_text'], article['source'])
        summary = get_summary(article['full_text'])
        
        st.sidebar.title("ğŸ¤– AI Insight")
        
        # 1. ì‹ ë¢°ë„ ë©”ì¸ ìŠ¤ì½”ì–´ (ê²Œì´ì§€ ìŠ¤íƒ€ì¼)
        st.sidebar.subheader("ğŸ›¡ï¸ ì‹ ë¢°ë„ ë¶„ì„ (TELLER)")
        score = trust_info.get('score', 0)
        
        # ì ìˆ˜ì— ë”°ë¥¸ ìƒ‰ìƒ/ìƒíƒœ ê²°ì •
        if score >= 70:
            score_color = "green"
            score_delta = "ì•ˆì „ (Safe)"
        elif score >= 40:
            score_color = "off" # íšŒìƒ‰/ë…¸ë€ìƒ‰ ê³„ì—´
            score_delta = "ì£¼ì˜ (Caution)"
        else:
            score_color = "inverse" # ë¹¨ê°„ìƒ‰ ê³„ì—´
            score_delta = "ìœ„í—˜ (Danger)"

        st.sidebar.metric(
            label="ì¢…í•© ì‹ ë¢°ë„ ì ìˆ˜",
            value=f"{score}ì ",
            delta=score_delta,
            delta_color=score_color
        )
        
        # ì ìˆ˜ ë°” (ì‹œê°ì  ì²´ê°)
        st.sidebar.progress(score / 100)

        st.sidebar.markdown("---")

        # 2. 5ëŒ€ í‰ê°€ ê¸°ì¤€ ìƒì„¸ (ì•„ì½”ë””ì–¸ ìŠ¤íƒ€ì¼)
        st.sidebar.subheader("ğŸ“Š ìƒì„¸ í‰ê°€ ë¦¬í¬íŠ¸")
        
        per_criteria = trust_info.get('per_criteria', {})
        
        # ë§¤í•‘: (í‚¤ -> í•œê¸€ ëª…ì¹­)
        criteria_map = {
            "source_credibility": "ğŸ“° ì¶œì²˜ ì‹ ë¢°ë„",
            "evidence_support": "ğŸ” ì¦ê±° ê¸°ë°˜ì„±",
            "style_neutrality": "âš–ï¸ í‘œí˜„ ì¤‘ë¦½ì„±",
            "logical_consistency": "ğŸ§  ë…¼ë¦¬ ì¼ê´€ì„±",
            "clickbait_risk": "ğŸ£ ë‚šì‹œì„±(Clickbait) ì—†ìŒ" 
            # ì£¼ì˜: ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ë‚šì‹œì„±ì´ 'ì—†ë‹¤(ì¢‹ë‹¤)'ëŠ” ëœ»ìœ¼ë¡œ í•´ì„
        }

        if not per_criteria:
            st.sidebar.warning("ìƒì„¸ í‰ê°€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for key, label_kr in criteria_map.items():
                item = per_criteria.get(key, {})
                # ë°©ì–´ ë¡œì§: itemì´ dictê°€ ì•„ë‹ ê²½ìš° ëŒ€ë¹„
                if not isinstance(item, dict):
                    s_score = 0
                    s_reason = "ë°ì´í„° ì˜¤ë¥˜"
                else:
                    s_score = item.get('score', 0)
                    s_reason = item.get('reason', 'ê·¼ê±° ì—†ìŒ')

                # 0~2ì ì„ ì•„ì´ì½˜ìœ¼ë¡œ ë³€í™˜
                icon_map = {2: "ğŸŸ¢ (ìš°ìˆ˜)", 1: "ğŸŸ¡ (ë³´í†µ)", 0: "ğŸ”´ (ë¯¸í¡/ì˜ì‹¬)"}
                status_text = icon_map.get(s_score, "âšª (ë¯¸ìƒ)")
                
                # Expanderë¡œ ê¹”ë”í•˜ê²Œ ì ‘ê¸°/í¼ì¹˜ê¸°
                with st.sidebar.expander(f"{label_kr}: {status_text}"):
                    st.markdown(f"**í‰ê°€ ê·¼ê±°:**\n\n{s_reason}")

        st.sidebar.markdown("---")

        # 3. ì¢…í•© ì½”ë©˜íŠ¸ (ê°€ë…ì„± ê°œì„ )
        st.sidebar.subheader("ğŸ“ ì¢…í•© ì½”ë©˜íŠ¸")
        overall_reason = trust_info.get('reason', '')
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¤„ë°”ê¿ˆí•˜ì—¬ ê°€ë…ì„± í™•ë³´
        formatted_reason = overall_reason.replace(". ", ".\n\n")
        
        if score >= 70:
            st.sidebar.success(formatted_reason)
        elif score >= 40:
            st.sidebar.warning(formatted_reason)
        else:
            st.sidebar.error(formatted_reason)

        st.sidebar.divider() 
        st.sidebar.subheader("ğŸ“‘ 3ì¤„ ìš”ì•½")
        st.sidebar.info(summary)

    else:
        st.error("ì˜¤ë¥˜: ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.button("â€¹ ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=show_main_page)


def render_search_results_page(query: str):
    """ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    st.subheader(f"'{query}' ê²€ìƒ‰ ê²°ê³¼ (v0.1 ë”ë¯¸)")
    st.markdown("v0.1ì—ì„œëŠ” ê²€ìƒ‰ì–´ì™€ ìƒê´€ì—†ì´ **ëª¨ë“  ê¸°ì‚¬(DB ì „ì²´)**ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
    
    all_articles = get_all_articles() 
    st.markdown(f"ì´ {len(all_articles)}ê°œì˜ (ê°€ì§œ) ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.")
    
    for article in all_articles:
        st.button(
            f"[{article['source']}] {article['title']}", 
            on_click=select_article, 
            args=(article['id'],), 
            key=article['id'],
            use_container_width=True
        )
    
    st.markdown("---")
    st.button("â€¹ ë©”ì¸ìœ¼ë¡œ ëŒì•„ê°€ê¸°", on_click=show_main_page)


def render_main_page():
    """ë©”ì¸(ëœë”©) í˜ì´ì§€ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤."""
    
    title_col, button_col = st.columns([0.8, 0.2])
    with title_col:
        st.title("ğŸ¤– AI ê¸°ë°˜ ë‰´ìŠ¤ ê²€ìƒ‰ í”Œë«í¼")
    with button_col:
        st.button(
            "ğŸ› ï¸ Manage Mode", 
            on_click=go_to_admin,
            use_container_width=True
        )
    st.markdown("---") 

    with st.form(key="search_form"):
        st.session_state.search_query = st.text_input(
            "ë¬´ì—‡ì´ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?", 
            value=st.session_state.search_query,
            placeholder="v0.1ì—ì„œëŠ” ì–´ë–¤ ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ë„ ëª¨ë“  ê¸°ì‚¬ê°€ ë‚˜ì˜µë‹ˆë‹¤."
        )
        submitted = st.form_submit_button(
            label="ğŸ” ê²€ìƒ‰", 
            on_click=execute_search,
            use_container_width=True
        )
    st.markdown("---")
    
    st.subheader("ë‹¹ì‹ ì„ ìœ„í•œ ìµœì‹  ì¶”ì²œ ë‰´ìŠ¤ (Dummy ì¶”ì²œ)")
    recommended_articles = get_recommendations(user_id="dummy_user")
    
    for article in recommended_articles:
        st.button(
            f"[{article['source']}] {article['title']}", 
            on_click=select_article,
            args=(article['id'],), 
            key=article['id'],
            use_container_width=True
        )
